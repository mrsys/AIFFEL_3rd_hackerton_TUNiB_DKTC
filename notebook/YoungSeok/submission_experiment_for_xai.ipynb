{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sda96/AIFFEL_3rd_hackerton_TUNiB_DKTC/blob/main/notebook/ChangHyun/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "view-in-github"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcMjKvuQWOHK"
      },
      "source": [
        "## 1. 환경 설정"
      ],
      "id": "YcMjKvuQWOHK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mclJrkru5cSV"
      },
      "source": [
        "필요한 패키지 불러오기"
      ],
      "id": "mclJrkru5cSV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g01yla0190IH",
        "outputId": "8aa93318-d318-493c-ef93-11297f25fff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 81.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 66.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.16.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 630 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 74.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n",
            "Collecting transformers-interpret\n",
            "  Downloading transformers-interpret-0.6.0.tar.gz (35 kB)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from transformers-interpret) (4.16.2)\n",
            "Collecting captum>=0.3.1\n",
            "  Downloading captum-0.4.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers-interpret) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers-interpret) (1.10.0+cu111)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers-interpret) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->captum>=0.3.1->transformers-interpret) (3.10.0.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.11.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.0.47)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (4.11.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.0.0->transformers-interpret) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0->transformers-interpret) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum>=0.3.1->transformers-interpret) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->transformers-interpret) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->transformers-interpret) (1.1.0)\n",
            "Building wheels for collected packages: transformers-interpret\n",
            "  Building wheel for transformers-interpret (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-interpret: filename=transformers_interpret-0.6.0-py3-none-any.whl size=30723 sha256=8fc3946571988cca8d460ef32e298e8a74b72876335f11ade8dc2466d26a60d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/d9/23/f98fc0716eaab211a43aa7531c9b096df60dd34d1f0ec316bd\n",
            "Successfully built transformers-interpret\n",
            "Installing collected packages: captum, transformers-interpret\n",
            "Successfully installed captum-0.4.1 transformers-interpret-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install konlpy\n",
        "!pip install transformers-interpret"
      ],
      "id": "g01yla0190IH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN4hwQ3E7zuJ"
      },
      "source": [
        "matplotlib 한글 깨짐 해결"
      ],
      "id": "CN4hwQ3E7zuJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9TBikq58c2N",
        "outputId": "f60b806a-cb33-4e92-9302-5154f8f22847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 1s (6,506 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "id": "G9TBikq58c2N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utcHQOr274zw"
      },
      "source": [
        "mecab 설치"
      ],
      "id": "utcHQOr274zw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TxDzWEh74LR",
        "outputId": "76767c83-8457-43de-dd7a-75e7a21d8ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.58.0-2ubuntu3.16).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.9).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Installing automake (A dependency for mecab-ko)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [76.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,596 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,474 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [806 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [931 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:19 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [840 kB]\n",
            "Get:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,827 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,035 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,252 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [936 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 15.1 MB in 3s (4,423 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  autoconf autotools-dev libsigsegv2 m4\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autotools-dev libsigsegv2 m4\n",
            "0 upgraded, 5 newly installed, 0 to remove and 75 not upgraded.\n",
            "Need to get 1,082 kB of archives.\n",
            "After this operation, 3,994 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Fetched 1,082 kB in 1s (1,019 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "(Reading database ... 155338 files and directories currently installed.)\n",
            "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Install mecab-ko\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1381k  100 1381k    0     0  2330k      0 --:--:-- --:--:-- --:--:-- 15.1M\n",
            "mecab-0.996-ko-0.9.2/\n",
            "mecab-0.996-ko-0.9.2/example/\n",
            "mecab-0.996-ko-0.9.2/example/example.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.2/example/example.c\n",
            "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.2/mecab-config.in\n",
            "mecab-0.996-ko-0.9.2/man/\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/man/mecab.1\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.2/config.guess\n",
            "mecab-0.996-ko-0.9.2/README\n",
            "mecab-0.996-ko-0.9.2/COPYING\n",
            "mecab-0.996-ko-0.9.2/CHANGES.md\n",
            "mecab-0.996-ko-0.9.2/README.md\n",
            "mecab-0.996-ko-0.9.2/INSTALL\n",
            "mecab-0.996-ko-0.9.2/config.sub\n",
            "mecab-0.996-ko-0.9.2/configure.in\n",
            "mecab-0.996-ko-0.9.2/swig/\n",
            "mecab-0.996-ko-0.9.2/swig/Makefile\n",
            "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.2/swig/version.h\n",
            "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.2/aclocal.m4\n",
            "mecab-0.996-ko-0.9.2/LGPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/configure\n",
            "mecab-0.996-ko-0.9.2/tests/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/t9/\n",
            "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test\n",
            "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/eval/\n",
            "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.2/tests/eval/system\n",
            "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/latin/\n",
            "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test\n",
            "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/ltmain.sh\n",
            "mecab-0.996-ko-0.9.2/config.rpath\n",
            "mecab-0.996-ko-0.9.2/config.h.in\n",
            "mecab-0.996-ko-0.9.2/mecabrc.in\n",
            "mecab-0.996-ko-0.9.2/GPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.train\n",
            "mecab-0.996-ko-0.9.2/ChangeLog\n",
            "mecab-0.996-ko-0.9.2/install-sh\n",
            "mecab-0.996-ko-0.9.2/AUTHORS\n",
            "mecab-0.996-ko-0.9.2/doc/\n",
            "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/posid.html\n",
            "mecab-0.996-ko-0.9.2/doc/unk.html\n",
            "mecab-0.996-ko-0.9.2/doc/learn.html\n",
            "mecab-0.996-ko-0.9.2/doc/format.html\n",
            "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.2/doc/feature.html\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/doc/soft.html\n",
            "mecab-0.996-ko-0.9.2/doc/en/\n",
            "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.2/doc/flow.png\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/result.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic.html\n",
            "mecab-0.996-ko-0.9.2/doc/partial.html\n",
            "mecab-0.996-ko-0.9.2/doc/feature.png\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/missing\n",
            "mecab-0.996-ko-0.9.2/BSD\n",
            "mecab-0.996-ko-0.9.2/NEWS\n",
            "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.2/src/\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.h\n",
            "mecab-0.996-ko-0.9.2/src/utils.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/make.bat\n",
            "mecab-0.996-ko-0.9.2/src/mecab.h\n",
            "mecab-0.996-ko-0.9.2/src/freelist.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/darts.h\n",
            "mecab-0.996-ko-0.9.2/src/param.h\n",
            "mecab-0.996-ko-0.9.2/src/char_property.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/winmain.h\n",
            "mecab-0.996-ko-0.9.2/src/thread.h\n",
            "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/src/connector.h\n",
            "mecab-0.996-ko-0.9.2/src/common.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.2/src/ucs.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/param.cpp\n",
            "mecab-0.996-ko-0.9.2/src/context_id.h\n",
            "mecab-0.996-ko-0.9.2/src/mmap.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.2/Makefile.in\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for egrep... /bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /bin/sed\n",
            "checking for fgrep... /bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "./configure: line 7378: /usr/bin/file: No such file or directory\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
            "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
            "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
            "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
            "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "libtool: link: ranlib .libs/libmecab.a\n",
            "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Install mecab-ko-dic\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 47.4M  100 47.4M    0     0  44.5M      0  0:00:01  0:00:01 --:--:--  105M\n",
            "mecab-ko-dic-2.1.1-20180720/\n",
            "mecab-ko-dic-2.1.1-20180720/configure\n",
            "mecab-ko-dic-2.1.1-20180720/COPYING\n",
            "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
            "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/README\n",
            "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
            "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
            "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/clean\n",
            "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
            "mecab-ko-dic-2.1.1-20180720/J.csv\n",
            "mecab-ko-dic-2.1.1-20180720/.keep\n",
            "mecab-ko-dic-2.1.1-20180720/feature.def\n",
            "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
            "mecab-ko-dic-2.1.1-20180720/dicrc\n",
            "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
            "mecab-ko-dic-2.1.1-20180720/model.def\n",
            "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
            "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
            "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
            "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
            "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
            "mecab-ko-dic-2.1.1-20180720/unk.def\n",
            "mecab-ko-dic-2.1.1-20180720/missing\n",
            "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/install-sh\n",
            "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
            "mecab-ko-dic-2.1.1-20180720/tools/\n",
            "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
            "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
            "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/char.def\n",
            "mecab-ko-dic-2.1.1-20180720/NEWS\n",
            "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
            "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/lib\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./MM.csv ... 453\n",
            "reading ./J.csv ... 416\n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./NR.csv ... 482\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./NP.csv ... 342\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./XR.csv ... 3637\n",
            "reading ./EP.csv ... 51\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./VX.csv ... 125\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./XSN.csv ... 124\n",
            "reading ./VA.csv ... 2360\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "Install mecab-python\n",
            "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Cloning into 'mecab-python-0.996'...\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Processing /tmp/mecab-python-0.996\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141814 sha256=4a096bf83b5833adfa2f4b299688640d337d12df746c8feb1744175a9741e567\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "    Running setup.py install for mecab-python ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install curl git\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "id": "4TxDzWEh74LR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUtVJiH59ASm"
      },
      "source": [
        "#### 해당 [사이트](https://teddylee777.github.io/colab/colab-korean)를 참고하여 위의 코드를 실행한 다음 런타임 재시작을 해주어야 합니다."
      ],
      "id": "oUtVJiH59ASm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "5Z2owJw-50vM",
        "outputId": "698053ca-0aaf-40d9-8049-7c88dfd3b5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans.\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44032 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45208 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46972 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans.\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44032 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45208 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46972 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 한글 지원 폰트\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# 마이너스 부호 \n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "plt.plot(np.random.randint(1, 50, 25))\n",
        "plt.title(\"가나다라\")\n",
        "plt.show()"
      ],
      "id": "5Z2owJw-50vM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSbnI8rRUGMm"
      },
      "source": [
        "#### 구글 드라이브와 코랩 연결"
      ],
      "id": "QSbnI8rRUGMm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Aohacm9kptzv",
        "outputId": "02a2af9d-9da8-4036-b1cc-5e12bfecdd06"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-037e20d03e0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/data/changhyun'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 135\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/data/changhyun')"
      ],
      "id": "Aohacm9kptzv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp5OFUaQSr1W",
        "outputId": "36fb1676-4621-4055-ae78-660278b4361d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data/changhyun\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ],
      "id": "tp5OFUaQSr1W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3RqqFg2aRuO",
        "outputId": "7df29555-91f9-4798-f8f6-bb800df56ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " config.json\t\t\t  'tokenizer_config.json의 사본'\n",
            "'special_tokens_map.json의 사본'  'tokenizer.json의 사본'\n",
            " tf_model.h5\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ],
      "id": "A3RqqFg2aRuO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7C236xgpKES"
      },
      "source": [
        "## 2. 데이터 불러오기"
      ],
      "id": "n7C236xgpKES"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UvhY-MNVfHJH"
      },
      "id": "UvhY-MNVfHJH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzmg7UqEzUaS"
      },
      "source": [
        "#### TUNiB 데이터 불러오기"
      ],
      "id": "rzmg7UqEzUaS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "NE4rkAdDC-F_",
        "outputId": "391e2771-e227-4711-c34f-f62f96ce9d32"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f25f084e034c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtunib_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/TUNiB/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtunib_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtunib_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conversation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/TUNiB/train.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tunib_train = pd.read_csv(\"../../data/TUNiB/train.csv\")\n",
        "tunib_train = tunib_train[[\"class\", \"conversation\"]]"
      ],
      "id": "NE4rkAdDC-F_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Dpl1IqY_09"
      },
      "source": [
        "#### 증강 데이터 불러오기"
      ],
      "id": "A6Dpl1IqY_09"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "alllWYBfU2y9",
        "outputId": "8f85a242-d72b-4775-b901-e54df27df0ff"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-b8b87e600032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0maug_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maug_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0maug_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maug_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"x_train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"conversation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y_train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0maug_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maug_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conversation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0maug_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['class', 'conversation'], dtype='object')] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "\n",
        "aug_path = glob(\"../../data/augmented_files/*\")\n",
        "bt_aug_path = [path for path in aug_path if \"bt\" in path]\n",
        "\n",
        "aug_train = pd.DataFrame()\n",
        "for path in bt_aug_path:\n",
        "  tmp = pd.read_csv(path, index_col = [0])\n",
        "  aug_train = pd.concat([aug_train, tmp], axis = 0)\n",
        "\n",
        "aug_train = aug_train.reset_index(drop=True)\n",
        "aug_train = aug_train.rename(columns = {\"x_train\":\"conversation\", \"y_train\":\"class\"})\n",
        "aug_train = aug_train[[\"class\", \"conversation\"]]\n",
        "print(aug_train.shape)\n",
        "aug_train.head()"
      ],
      "id": "alllWYBfU2y9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0goi1T2p9zWm"
      },
      "outputs": [],
      "source": [
        "def id2label(x):\n",
        "  # id에 맞는 실제 클래스로 변환시킵니다.\n",
        "  if x == 0:\n",
        "    return \"협박 대화\"\n",
        "  elif x == 1:\n",
        "    return \"갈취 대화\"\n",
        "  elif x == 2:\n",
        "    return \"직장 내 괴롭힘 대화\"\n",
        "  elif x == 3:\n",
        "    return \"기타 괴롭힘 대화\"\n",
        "  elif x == 4:\n",
        "    return \"일반 대화\""
      ],
      "id": "0goi1T2p9zWm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao0Ap9If9s51"
      },
      "outputs": [],
      "source": [
        "aug_train[\"class\"] = aug_train[\"class\"].apply(id2label)\n",
        "aug_train.head()"
      ],
      "id": "ao0Ap9If9s51"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yFmsUOAXDhi"
      },
      "outputs": [],
      "source": [
        "total_data = pd.read_csv(\"../../data/senti_kor_sns_5000.csv\", index_col = [0])\n",
        "print(len(total_data))\n",
        "total_data = pd.concat([total_data, aug_train], axis = 0)\n",
        "total_data = total_data.reset_index(drop=True)\n",
        "total_data"
      ],
      "id": "7yFmsUOAXDhi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY-ES6-2YUxh"
      },
      "outputs": [],
      "source": [
        "total_data.to_csv(\"../../data/senti_kor_sns_5000_bt.csv\")"
      ],
      "id": "RY-ES6-2YUxh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbPmgK3izeMI"
      },
      "source": [
        "#### AI_HUB 데이터 불러오기"
      ],
      "id": "lbPmgK3izeMI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RNrjm8WUT2v"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "aihub_train_path = glob(\"../../data/AI_HUB/*\")\n",
        "\n",
        "aihub_train = pd.DataFrame()\n",
        "for path in aihub_train_path:\n",
        "  tmp = pd.read_csv(path)[[\"class\", \"conversation\"]]\n",
        "  if len(tmp) >= 5000:\n",
        "    tmp = tmp.sample(5000)\n",
        "    aihub_train = pd.concat([aihub_train, tmp], axis = 0)\n",
        "  else:\n",
        "    aihub_train = pd.concat([aihub_train, tmp], axis = 0)"
      ],
      "id": "2RNrjm8WUT2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2WYJUbBWOjr"
      },
      "outputs": [],
      "source": [
        "aihub_train = aihub_train.drop_duplicates(keep=\"first\")\n",
        "aihub_train"
      ],
      "id": "K2WYJUbBWOjr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDae3grfzlHj"
      },
      "source": [
        "#### AI_HUB 데이터와 TUNiB 데이터를 합친 뒤 전처리 적용"
      ],
      "id": "kDae3grfzlHj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE1S8foOdrA3"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([tunib_train, aug_train, aihub_train], axis = 0)\n",
        "train"
      ],
      "id": "ZE1S8foOdrA3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlJIKW4o9YyA"
      },
      "outputs": [],
      "source": [
        "train.groupby(\"class\").count()"
      ],
      "id": "VlJIKW4o9YyA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVxs0na9PpPn"
      },
      "outputs": [],
      "source": [
        "def label2id(x):\n",
        "  # id에 맞는 실제 클래스로 변환시킵니다.\n",
        "  if x == \"협박 대화\":\n",
        "    return 0\n",
        "  elif x == \"갈취 대화\":\n",
        "    return 1\n",
        "  elif x == \"직장 내 괴롭힘 대화\":\n",
        "    return 2\n",
        "  elif x == \"기타 괴롭힘 대화\":\n",
        "    return 3\n",
        "  elif x == \"일반 대화\":\n",
        "    return 4\n",
        "\n",
        "def preprocessing(x):\n",
        "  # 한글, 숫자, ?!,. 를 제외하고는 모든 str을 공백으로 대체합니다.\n",
        "  x = re.sub(\"[^ㄱ-ㅎ가-힣0-9?!,.]\", \" \", x)\n",
        "  # 연속적인 공백을 한칸 공백으로 대체합니다.\n",
        "  x = re.sub(\"[ ]+\", \" \", x)\n",
        "  # 양쪽 공백을 제거합니다.\n",
        "  x = x.strip()\n",
        "  return x"
      ],
      "id": "dVxs0na9PpPn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ssHh3qPrkH"
      },
      "outputs": [],
      "source": [
        "# 앞선 함수를 데이터셋에 적용합니다.\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "train[\"class\"] = train[\"class\"].apply(label2id)\n",
        "tqdm.pandas()\n",
        "train[\"conversation\"] = train[\"conversation\"].progress_apply(preprocessing)\n",
        "train = train.reset_index(drop=True)\n",
        "train.head()"
      ],
      "id": "F_ssHh3qPrkH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPS_8rY-PZxC"
      },
      "outputs": [],
      "source": [
        "train.groupby(\"class\").count()"
      ],
      "id": "EPS_8rY-PZxC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VmM0cN00Ojg"
      },
      "source": [
        "#### 학습을 위해서 만들어진 데이터셋 csv 파일로 저장"
      ],
      "id": "2VmM0cN00Ojg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfPKmv8RQzbQ"
      },
      "outputs": [],
      "source": [
        "train.to_csv(\"../../data/senti_kor_sns_summary_5000_bt.csv\")"
      ],
      "id": "nfPKmv8RQzbQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "executive-tumor"
      },
      "source": [
        "## 3. 모델 클래스 및 함수 "
      ],
      "id": "executive-tumor"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSfkbxNodTU-"
      },
      "source": [
        "#### 데이터 로딩 클래스"
      ],
      "id": "YSfkbxNodTU-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_SF3-cYvn6p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "class DataLoad():\n",
        "\n",
        "\n",
        "  def __init__(self, data_path):\n",
        "    self.dataset = pd.read_csv(data_path)\n",
        "\n",
        "\n",
        "  def split(self, split_size):\n",
        "    X = self.dataset[\"conversation\"]\n",
        "    Y = self.dataset[\"class\"]\n",
        "    print(self.dataset.groupby(\"class\").count().iloc[:,0])\n",
        "    print(self.dataset.head())\n",
        "    # 전체 데이터의 split_size 비율 만큼은 테스트, 검증 데이터입니다.\n",
        "    x_train, x_val_test, y_train, y_val_test = train_test_split(X, Y, \n",
        "                                                            test_size = split_size, \n",
        "                                                            random_state = 200,\n",
        "                                                            stratify = Y)\n",
        "    # 테스트, 검증 데이터의 개수는 1:1의 비율을 가집니다.\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test,\n",
        "                                                test_size = 0.5,\n",
        "                                                random_state = 202,\n",
        "                                                stratify = y_val_test)\n",
        "    print(f\"x_train 개수 : {len(x_train)}\")\n",
        "    print(f\"y_train 개수 : {len(y_train)}\")\n",
        "    print(f\"x_val 개수 : {len(x_val)}\")\n",
        "    print(f\"y_val 개수 : {len(y_val)}\")\n",
        "    print(f\"x_test 개수 : {len(x_test)}\")\n",
        "    print(f\"y_test 개수 : {len(y_test)}\")\n",
        "    print(f\"훈련 데이터 레이블 비율 확인 : {Counter(y_train)}\")\n",
        "    print(f\"검증 데이터 레이블 비율 확인 : {Counter(y_val)}\")\n",
        "    print(f\"테스트 데이터 레이블 비율 확인 : {Counter(y_test)}\")\n",
        "    return x_train.tolist(), x_val.tolist(), x_test.tolist(), y_train.tolist(), y_val.tolist(), y_test.tolist()"
      ],
      "id": "A_SF3-cYvn6p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGnVrUzRdZCX"
      },
      "source": [
        "#### 데이터 증강 클래스"
      ],
      "id": "LGnVrUzRdZCX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSZTawMxU113"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import gensim\n",
        "from konlpy.tag import Mecab\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DataAugmentation:\n",
        "\n",
        "\n",
        "  def __init__(self, X, Y, word2vec_path):\n",
        "    self.mecab = Mecab()\n",
        "    self.word2vec = gensim.models.Word2Vec.load(word2vec_path)\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "  \n",
        "  def sub_rep(self, X, sub_ratio = 0.1):\n",
        "    # 전체 단어중에서 sub_ratio 만큼만 무작위 선택합니다.\n",
        "    nouns = list(set(self.mecab.morphs(X)))\n",
        "    sub_num = int(len(nouns) * sub_ratio)\n",
        "    sub_list = random.sample(nouns, sub_num)\n",
        "\n",
        "    # 대체 시킬 단어와 유사한 단어들을 불러옵니다.\n",
        "    result = []\n",
        "    for sub in sub_list:\n",
        "      try:\n",
        "        result.append((sub, self.word2vec.wv.most_similar(sub)[0]))\n",
        "      except KeyError:\n",
        "        pass\n",
        "    result = list(map(lambda x: (x[0], x[1][0]), result))\n",
        "\n",
        "    # 무작위 선택된 단어들을 유사한 단어들로 바꿔줍니다.\n",
        "    for before, after in result:\n",
        "      X = X.replace(before, after, 1)\n",
        "    return X\n",
        "\n",
        "  def sub_rep_dataset(self, sub_ratio = 0.1):\n",
        "    # 입력 X에 sub_rep 함수 적용합니다.\n",
        "    new_x = list(tqdm(map(lambda x: self.sub_rep(x, sub_ratio), self.X)))\n",
        "    # 입력 Y의 값을 복사합니다.\n",
        "    new_y = self.Y.copy()\n",
        "\n",
        "    print(\"훈련 데이터 유의어 대체 증강 완료\")\n",
        "    print(f\"증강시킨 데이터 개수 : {len(new_x)}\")\n",
        "    print(f\"----데이터 증강 전 데이터 예시 ----\\n{self.X[0]}\")\n",
        "    print(f\"----데이터 증강 후 데이터 예시 ----\\n{new_x[0]}\")\n",
        "    return new_x, new_y\n",
        "\n",
        "  def label_repeat(self, label_id, num = 1):\n",
        "    # 특정 레이블 label_id를 num 횟수 만큼 반복\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    for i in range(num):\n",
        "      label_index = (np.array(self.Y) == label_id)\n",
        "      new_x += np.array(self.X)[label_index].tolist()\n",
        "      new_y += np.array(self.Y)[label_index].tolist()\n",
        "    \n",
        "    print(\"훈련 데이터 특정 레이블 반복 증강 완료\")\n",
        "    print(f\"반복되는 레이블 id : {label_id}\")\n",
        "    print(f\"반복된 횟수 : {num}\")\n",
        "    return new_x, new_y"
      ],
      "id": "VSZTawMxU113"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWcWSHaTdoiU"
      },
      "source": [
        "#### 기타 함수 "
      ],
      "id": "rWcWSHaTdoiU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAPJD_j6qPLZ"
      },
      "outputs": [],
      "source": [
        "def id2label(x):\n",
        "  # id에 맞는 실제 클래스로 변환시킵니다.\n",
        "  if x == 0:\n",
        "    return \"협박 대화\"\n",
        "  elif x == 1:\n",
        "    return \"갈취 대화\"\n",
        "  elif x == 2:\n",
        "    return \"직장 내 괴롭힘 대화\"\n",
        "  elif x == 3:\n",
        "    return \"기타 괴롭힘 대화\"\n",
        "  elif x == 4:\n",
        "    return \"일반 대화\"\n",
        "\n",
        "\n",
        "def clf_score(y_test, y_pred):\n",
        "  # 테스트 데이터에서 오분류된 데이터들의 idx를 리스트 타입으로 반환합니다.\n",
        "  # classification report \n",
        "  false_list = [idx for idx, i in enumerate(y_test) if y_pred[idx] != i]\n",
        "  print(f\"모델이 틀린 데이터 개수 {len(false_list)}개\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  # confusion matrix\n",
        "  conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  names = [\"협박\", \"갈취\", \"직장내 괴롭힘\", \"기타 괴롭힘\", \"일반\"]\n",
        "  conf_matrix = pd.DataFrame(conf_matrix, index = names, columns = names)\n",
        "  sns.heatmap(conf_matrix, annot = True, fmt = \"d\")\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.xlabel(\"pred\")\n",
        "  plt.ylabel(\"true\")\n",
        "  plt.show()\n",
        "  return false_list\n",
        "\n",
        "\n",
        "def evaluate_result(score_list, x_test, y_pred, y_test):\n",
        "  # 입력, 예측값, 실제값, 레이블별 score로 이루어진 판다스 데이터셋을 반환합니다.\n",
        "  score_dataset = pd.DataFrame(score_list).add_prefix(\"label_\")\n",
        "  label_dataset = pd.DataFrame({\"x_test\":x_test, \"y_pred\":y_pred, \"y_test\":y_test})\n",
        "  test_dataset = pd.concat([label_dataset, score_dataset], axis = 1)\n",
        "  return test_dataset\n",
        "\n",
        "\n",
        "def false_case_dataset(false_list, x_test, y_test, y_pred, print_example = False):\n",
        "  # 오분류된 idx에 맞는 입력, 예측값, 실제값을 담은 리스트를 반환합니다.\n",
        "  false_x_test = [x_test[i] for i in false_list]\n",
        "  false_y_test = [y_test[i] for i in false_list]\n",
        "  false_y_pred = [y_pred[i] for i in false_list]\n",
        "\n",
        "  # 앞서 담은 리스트들을 판다스 데이터프레임 타입으로 변환시킵니다.\n",
        "  false_dataset = pd.DataFrame({\"text\":false_x_test, \"y_true\":false_y_test, \"y_pred\":false_y_pred})\n",
        "  # 숫자로된 id를 실제 레이블로 바꾸며 예시는 '0 -> 협박 대화' 입니다.\n",
        "  false_dataset[\"y_true\"] = false_dataset[\"y_true\"].apply(lambda x : id2label(x))\n",
        "  false_dataset[\"y_pred\"] = false_dataset[\"y_pred\"].apply(lambda x : id2label(x))\n",
        "\n",
        "  # 오분류 예제의 내용을 보고 싶으면 print_example argument를 True로 바꿉니다.\n",
        "  if print_example:\n",
        "    for i in range(len(false_dataset)):\n",
        "      sentence, prediction, real =false_dataset.iloc[i, :]\n",
        "      print(f\"예측 분류 : {prediction}\")\n",
        "      print(f\"실제 분류 : {real}\")\n",
        "      print(sentence)\n",
        "      print(\"\\n\")\n",
        "  return false_dataset  \n",
        "\n",
        "\n",
        "def save_csv(df, path, name):\n",
        "  try:\n",
        "    os.mkdir(path)\n",
        "  except:\n",
        "    pass\n",
        "  new_path = os.path.join(path, name)\n",
        "  df.to_csv(new_path)\n",
        "\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 1:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * 0.2"
      ],
      "id": "LAPJD_j6qPLZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7Fmk8Z_ddet"
      },
      "source": [
        "#### Huggingface 모델 파이프라인 클래스"
      ],
      "id": "w7Fmk8Z_ddet"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hnts0NAvNXO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from transformers import TextClassificationPipeline\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, TFAutoModel\n",
        "\n",
        "\n",
        "class TFGPT2ForSequenceClassification(tf.keras.Model):\n",
        "  \"\"\"\n",
        "  GPT모델은 따로 출력층에 softmax 레이어를 추가해야 합니다.\n",
        "  \"\"\"\n",
        "  def __init__(self, model_name, num_labels):\n",
        "      super(TFGPT2ForSequenceClassification, self).__init__()\n",
        "      self.gpt = TFAutoModel.from_pretrained(model_name, \n",
        "                                              from_pt=True)\n",
        "      self.classifier = tf.keras.layers.Dense(num_labels,\n",
        "                                              kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
        "                                              activation='softmax',\n",
        "                                              name='classifier')\n",
        "\n",
        "  def call(self, inputs):\n",
        "      outputs = self.gpt(input_ids=inputs)\n",
        "      cls_token = outputs[0][:, -1]\n",
        "      prediction = self.classifier(cls_token)\n",
        "\n",
        "      return prediction\n",
        "\n",
        "\n",
        "class TrainPipeline:\n",
        "  def __init__(self, model_path, num_labels, batch_size = 16, epochs = 1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - model_path : Hugginface에서 사전학습된 모델들의 주소 str값을 받습니다.\n",
        "      - num_labels : 분류되는 클래스의 개수 int값을 받습니다.\n",
        "      - batch_size : 배치마다 들어가는 데이터의 개수 int값을 받습니다.\n",
        "      - epochs : 모델이 학습하는 에폭 수 int값을 받습니다.\n",
        "    Desc:\n",
        "      - 데이터셋 구축, 모델 훈련, 저장, 검증의 과정을 거치는 훈련 파이프라인\n",
        "    \"\"\"\n",
        "    self.model_path = model_path\n",
        "    self.batch_size = batch_size\n",
        "    self.epochs = epochs\n",
        "    self.num_labels = num_labels\n",
        "    if \"output_bert\" in self.model_path:\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\",\n",
        "                                                    bos_token='</s>', \n",
        "                                                    eos_token='</s>', \n",
        "                                                    pad_token='<pad>')\n",
        "    else:\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(self.model_path,\n",
        "                                                    bos_token='</s>', \n",
        "                                                    eos_token='</s>', \n",
        "                                                    pad_token='<pad>')\n",
        "    if \"output_bert\" in self.model_path:\n",
        "      self.model = TFAutoModelForSequenceClassification.from_pretrained(self.model_path,\n",
        "                                                                        num_labels = self.num_labels)\n",
        "    else:\n",
        "      self.model = TFAutoModelForSequenceClassification.from_pretrained(self.model_path,\n",
        "                                                                        num_labels = self.num_labels,\n",
        "                                                                        from_pt=True)\n",
        "    # https://stackoverflow.com/questions/69191305/how-to-add-new-special-token-to-the-tokenizer\n",
        "    # 추가된 토큰에 맞게 vocab_size 재지정\n",
        "    self.model.resize_token_embeddings(len(self.tokenizer))\n",
        "\n",
        "  def dataset(self, X, Y, lstm = False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - X : 모델의 입력 변수로 str문장들로 구성된 list를 받습니다.\n",
        "      - Y : 모델의 출력 변수로 id값으로 구성된 list를 받습니다.\n",
        "      - lstm : lstm모델 여부를 결정하는 arg로 boolean을 받습니다.\n",
        "    Desc:\n",
        "      - 모델 학습에 들어가기 직전의 데이터셋으로 변환시켜주는 메소드입니다.\n",
        "    Returns:\n",
        "      - 모델이 GPT이면 (2D-array, 1D-array) 형태의 튜플을 반환합니다.\n",
        "      - 모델이 BERT, LSTM이면 텐서플로우 데이터셋을 반환합니다.\n",
        "    \"\"\"\n",
        "    # GPT 모델인 경우 넘파이로 반환시킵니다.\n",
        "    if \"GPT\" in str(self.model):\n",
        "      # 입력 변수 X의 원소에 차례대로 토큰화를 시키고 list에 넣습니다.\n",
        "      input_ids, data_labels = [], []\n",
        "      for example, label in tqdm(zip(X, Y), total=len(X)):\n",
        "          bos_token = [self.tokenizer.bos_token]\n",
        "          eos_token = [self.tokenizer.eos_token]\n",
        "          tokens = bos_token + self.tokenizer.tokenize(example) + eos_token\n",
        "          input_id = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "          input_ids.append(input_id)\n",
        "          data_labels.append(label)\n",
        "\n",
        "      # X에 토큰화된 문장중에서 가장 긴 문장을 기준으로 패딩을 해줍니다.\n",
        "      max_seq_len = max(map(lambda x : len(x), input_ids))\n",
        "      input_ids = pad_sequences(input_ids, maxlen = max_seq_len, \n",
        "                                value = self.tokenizer.pad_token_id, \n",
        "                                padding='post')\n",
        "      data_labels = np.array(data_labels)\n",
        "      return input_ids, data_labels\n",
        "\n",
        "    # BERT 모델인 경우 텐서플로우 데이터셋으로 반환시킵니다.\n",
        "    if not lstm:\n",
        "      encodings = self.tokenizer(X, truncation = True, padding = True)\n",
        "      dataset = tf.data.Dataset.from_tensor_slices((dict(encodings), \n",
        "                                                          Y))\n",
        "      dataset = dataset.shuffle(1000).batch(self.batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # LSTM 모델인 경우 텐서플로우 데이터셋으로 반환시킵니다.\n",
        "    else:\n",
        "      encodings = X\n",
        "      dataset = tf.data.Dataset.from_tensor_slices((encodings, \n",
        "                                                    Y))\n",
        "      dataset = dataset.shuffle(1000).batch(self.batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset    \n",
        "\n",
        "  def training_dataset(self, train_dataset, val_dataset):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - train_dataset : dataset 메소드를 거친 훈련 데이터셋을 받습니다.\n",
        "      - val_dataset : dataset 메소드를 거친 검증 데이터셋을 받습니다.\n",
        "    Desc:\n",
        "      - 호출시킨 모델에 맞게 학습을 시키고 학습된 모델을 반환시켜줍니다.\n",
        "    Returns:\n",
        "      - 모델이 GPT면 학습된 subclass 모델을 반환합니다\n",
        "      - 모델이 LSTM, BERT이면 학습된 functional 모델을 반환합니다.\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "    losses = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                          mode='auto', \n",
        "                                          patience=1)\n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "    \n",
        "    # 모델이 GPT인 경우 앞서 선언된 subclass 모델을 가져와서 학습시킵니다.\n",
        "    if \"GPT\" in str(self.model):\n",
        "      x_train, y_train = train_dataset\n",
        "      x_val, y_val = val_dataset\n",
        "      num_labels = int(max(y_train) + 1)\n",
        "      self.model = TFGPT2ForSequenceClassification(self.model_path,\n",
        "                                              num_labels = num_labels)\n",
        "      self.model.compile(optimizer = optimizer,\n",
        "                        loss = losses,\n",
        "                        metrics = ['accuracy'])\n",
        "      self.model.fit(x_train, y_train,\n",
        "                     epochs = self.epochs,\n",
        "                     batch_size = self.batch_size,\n",
        "                     validation_data = (x_val, y_val),\n",
        "                     callbacks = [lr_schedule, es])\n",
        "      return self.model\n",
        "\n",
        "    # 모델이 LSTM, BERT인 경우 바로 학습시킵니다.\n",
        "    else:\n",
        "      self.model.compile(optimizer = optimizer,\n",
        "                        loss = losses,\n",
        "                        metrics = ['accuracy'])\n",
        "      self.model.fit(train_dataset,\n",
        "                     epochs = self.epochs,\n",
        "                     batch_size = self.batch_size,\n",
        "                     validation_data = val_dataset,\n",
        "                     callbacks = [lr_schedule, es])\n",
        "      return self.model \n",
        "\n",
        "  def evaluate_model(self, x_test):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - x_test : LSTM, GPT모델이면 2-D array의 테스트 데이터를 받습니다.\n",
        "    Desc:\n",
        "      - 학습된 모델에 x_test를 예측한 점수와 클래스를 반환합니다.\n",
        "    Returns:\n",
        "      - LSTM, GPT 모델이면 (예측 점수 list, 클래스 1D-array)인 튜플을 반환합니다.\n",
        "      - BERT 모델인 경우 (예측 점수 list, 클래스 list)인 튜플을 반환합니다.\n",
        "    \"\"\"\n",
        "    predicted_label_list = []\n",
        "    predicted_score_list = []\n",
        "    \n",
        "    # 테스트 데이터를 예측하는 모델이 LSTM 또는 GPT인 경우\n",
        "    if \"Functional\" in str(self.model) or \"GPT\" in str(self.model):\n",
        "      predicted_score_list = self.model.predict(x_test)\n",
        "      y_pred = np.argmax(predicted_score_list, axis = -1)\n",
        "      predicted_score_list = predicted_score_list.tolist()\n",
        "    \n",
        "    # 테스트 데이터를 예측하는 모델이 BERT인 경우\n",
        "    else:\n",
        "      clf_model = TextClassificationPipeline(\n",
        "          tokenizer = self.tokenizer,\n",
        "          model = self.model,\n",
        "          framework = \"tf\",\n",
        "          return_all_scores = True\n",
        "          )\n",
        "      for text in tqdm(x_test):\n",
        "          preds_list = clf_model(text)[0]\n",
        "          sorted_preds_list = max(preds_list, key=lambda x: x['score'])\n",
        "          predicted_label_list.append(sorted_preds_list[\"label\"]) # label\n",
        "          predicted_score_list.append(list(map(lambda x : x['score'], preds_list))) # score\n",
        "      y_pred = [int(label[-1]) for label in predicted_label_list]\n",
        "    return predicted_score_list, y_pred\n",
        "  \n",
        "  def save_model_tokenizer(self, save_path):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - save_path : 학습된 모델을 저장할 경로인 str를 받습니다.\n",
        "    Desc:\n",
        "      - save_path 경로에 폴더를 만들고 학습된 모델을 저장합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    # save_path에 맞는 새로운 경로를 만듭니다.\n",
        "    try:\n",
        "      os.mkdir(save_path)\n",
        "    except:\n",
        "      pass\n",
        "    \n",
        "    # 저장하는 모델이 GPT인 경우\n",
        "    if \"GPT\" in str(self.model):\n",
        "      folder_name = re.sub(\"/\", \"-\", self.model_path)\n",
        "      new_path = os.path.join(save_path, folder_name)\n",
        "      self.model.save_weights('path_to_my_weights', save_format='tf')\n",
        "\n",
        "    # 저장하는 모델이 LSTM인 경우\n",
        "    elif \"Functional\" in str(self.model):\n",
        "      new_path = os.path.join(save_path, \"LSTM.h5\", )\n",
        "      self.model.save(new_path)\n",
        "    \n",
        "    # 저장하는 모델이 BERT인 경우\n",
        "    else:\n",
        "      folder_name = re.sub(\"/\", \"-\", self.model_path)\n",
        "      new_path = os.path.join(save_path, folder_name)    \n",
        "      self.model.save_pretrained(new_path)\n",
        "      self.tokenizer.save_pretrained(new_path)"
      ],
      "id": "_hnts0NAvNXO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqYfxCinMdFa"
      },
      "source": [
        "## 4. Main Huggingface 함수"
      ],
      "id": "nqYfxCinMdFa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6AIlowf119l"
      },
      "source": [
        "현재 실험 중인 Hunggingface 모델은 다음과 같습니다.\n",
        "- \"klue/bert-base\"\n",
        "- \"skt/kogpt2-base-v2\"\n",
        "- \"monologg/koelectra-base-v3-discriminator\"\n",
        "- \"klue/roberta-base\"\n",
        "- \"distilbert-base-multilingual-cased\""
      ],
      "id": "w6AIlowf119l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7qLVXz6J2JP",
        "outputId": "9bce54a6-0acb-4e5d-f1c6-4c03f3b6a7e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.27.110.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.27.110.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.27.110.26:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.27.110.26:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./model/output_bert/ 파이프라인 시작\n",
            "class\n",
            "0     3584\n",
            "1     3924\n",
            "2     3916\n",
            "3     4376\n",
            "4    20341\n",
            "Name: Unnamed: 0, dtype: int64\n",
            "   Unnamed: 0  class                                       conversation\n",
            "0           0      0  지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼...\n",
            "1           1      0  길동경찰서입니다. 9시 40분 마트에 폭발물을 설치할거다. 네? 똑바로 들어 한번만...\n",
            "2           2      3  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어. 그만해. 니들 놀리는거 재미없...\n",
            "3           3      1  어이 거기 예?? 너 말이야 너. 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘 돈...\n",
            "4           4      1  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...\n",
            "x_train 개수 : 35779\n",
            "y_train 개수 : 35779\n",
            "x_val 개수 : 181\n",
            "y_val 개수 : 181\n",
            "x_test 개수 : 181\n",
            "y_test 개수 : 181\n",
            "훈련 데이터 레이블 비율 확인 : Counter({4: 20137, 3: 4332, 1: 3885, 2: 3877, 0: 3548})\n",
            "검증 데이터 레이블 비율 확인 : Counter({4: 102, 3: 22, 1: 20, 2: 19, 0: 18})\n",
            "테스트 데이터 레이블 비율 확인 : Counter({4: 102, 3: 22, 2: 20, 1: 19, 0: 18})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ./model/output_bert/ and are newly initialized: ['classifier', 'bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "2237/2237 [==============================] - 344s 117ms/step - loss: 0.2435 - accuracy: 0.9159 - val_loss: 0.1523 - val_accuracy: 0.9337 - lr: 5.0000e-05\n",
            "Epoch 2/4\n",
            "2237/2237 [==============================] - 251s 112ms/step - loss: 0.0639 - accuracy: 0.9787 - val_loss: 0.0421 - val_accuracy: 0.9834 - lr: 1.0000e-05\n",
            "Epoch 3/4\n",
            "2237/2237 [==============================] - 246s 110ms/step - loss: 0.0241 - accuracy: 0.9940 - val_loss: 0.0265 - val_accuracy: 0.9890 - lr: 2.0000e-06\n",
            "Epoch 4/4\n",
            "2237/2237 [==============================] - 245s 110ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.0264 - val_accuracy: 0.9945 - lr: 4.0000e-07\n",
            "./model/output_bert/ 파이프라인 종료\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Huggingface에서 사용 가능한 사전학습 모델 리스트입니다.\n",
        "model_paths = [\"./model/output_bert/\"]     \n",
        "\n",
        "\n",
        "save_path = \"./model/tmp\" # 모델이 저장되는 위치\n",
        "data_path = \"./senti_kor_sns_5000_bt_eco.csv\" # 학습 데이터 위치\n",
        "word2vec_path = \"./packages/ko.bin\" # 사전 학습 임베딩 벡터 저장 위치\n",
        "batch_size = 16 # 모델에 들어가는 배치 크기\n",
        "epochs = 4 # 에폭 수\n",
        "sub_ratio = [0.05, 0.1, 0.1]\n",
        "\n",
        "for model_path in model_paths:\n",
        "  # TPU 작동을 위한 코드\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "  with strategy.scope():\n",
        "    print(f\"{model_path} 파이프라인 시작\")\n",
        "\n",
        "    # 데이터 로딩\n",
        "    load = DataLoad(data_path)\n",
        "    x_train, x_val, x_test, y_train, y_val, y_test = load.split(0.01)\n",
        "    test_text = x_test.copy()\n",
        "    num_labels = int(max(y_train) + 1)\n",
        "\n",
        "    # # 협박 대화만 데이터 증강하기 위해서 걸러주기\n",
        "    # not_normal_x = []\n",
        "    # not_normal_y = []\n",
        "    # for x, y in zip(x_train, y_train):\n",
        "    #   # 일반 대화의 id는 4 입니다.\n",
        "    #   if y != 4:\n",
        "    #     not_normal_x.append(x)\n",
        "    #     not_normal_y.append(y)\n",
        "\n",
        "    # # 데이터 증강 : 무작위 단어 교체\n",
        "    # data_aug = DataAugmentation(not_normal_x, not_normal_y, word2vec_path)\n",
        "    # sub_rep_x = []\n",
        "    # sub_rep_y = []\n",
        "    # for i in sub_ratio:\n",
        "    #   tmp_x, tmp_y = data_aug.sub_rep_dataset(sub_ratio = i)\n",
        "    #   sub_rep_x += tmp_x\n",
        "    #   sub_rep_y += tmp_y\n",
        "\n",
        "    # # 증강된 데이터들 합치기\n",
        "    # x_train = x_train + sub_rep_x\n",
        "    # y_train = y_train + sub_rep_y\n",
        "\n",
        "    # print(f\"훈련 데이터 레이블 비율 확인 : {Counter(y_train)}\")\n",
        "\n",
        "    # 데이터셋 구축\n",
        "    pipeline = TrainPipeline(model_path, num_labels, batch_size, epochs)\n",
        "    train_dataset = pipeline.dataset(x_train, y_train)\n",
        "    val_dataset = pipeline.dataset(x_val, y_val)\n",
        "    if \"GPT\" in str(pipeline.model):\n",
        "      test_dataset = pipeline.dataset(x_test, y_test)\n",
        "      x_test, y_test = test_dataset\n",
        "\n",
        "    # 모델 학습, 예측, 저장\n",
        "    model = pipeline.training_dataset(train_dataset, val_dataset)\n",
        "    # score_list, y_pred = pipeline.evaluate_model(x_test)\n",
        "    # pipeline.save_model_tokenizer(save_path)\n",
        "\n",
        "    # 모델 검증    \n",
        "    # false_list = clf_score(y_test, y_pred)\n",
        "    # false_dataset = false_case_dataset(false_list, test_text, y_test, y_pred)\n",
        "    # eval_dataset = evaluate_result(score_list, test_text, y_pred, y_test)\n",
        "    # save_dataset_path = os.path.join(save_path, \"eval_result\")\n",
        "    # model_name = model_path.split(\"/\")[-1]\n",
        "    # save_csv(eval_dataset, save_dataset_path, f\"{model_name}.csv\")\n",
        "    \n",
        "    print(f\"{model_path} 파이프라인 종료\\n\")"
      ],
      "id": "a7qLVXz6J2JP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEJzZi5bLiF3"
      },
      "outputs": [],
      "source": [
        "save_path = \"./model/tapt_summary_model\"\n",
        "pipeline.save_model_tokenizer(save_path)"
      ],
      "id": "uEJzZi5bLiF3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrzwbLlJ0peJ"
      },
      "source": [
        "## 5. Attention을 활용한 XAI 시각화"
      ],
      "id": "QrzwbLlJ0peJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Px3nAKiTEOe",
        "outputId": "0813224e-31b7-4718-c7a5-74ebb18bf4fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class\n",
            "0     3584\n",
            "1     3924\n",
            "2     3916\n",
            "3     4376\n",
            "4    15346\n",
            "Name: Unnamed: 0, dtype: int64\n",
            "   Unnamed: 0  class                                       conversation\n",
            "0           0      0  지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼...\n",
            "1           1      0  길동경찰서입니다. 9시 40분 마트에 폭발물을 설치할거다. 네? 똑바로 들어 한번만...\n",
            "2           2      3  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어. 그만해. 니들 놀리는거 재미없...\n",
            "3           3      1  어이 거기 예?? 너 말이야 너. 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘 돈...\n",
            "4           4      1  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...\n",
            "x_train 개수 : 30834\n",
            "y_train 개수 : 30834\n",
            "x_val 개수 : 156\n",
            "y_val 개수 : 156\n",
            "x_test 개수 : 156\n",
            "y_test 개수 : 156\n",
            "훈련 데이터 레이블 비율 확인 : Counter({4: 15192, 3: 4332, 1: 3885, 2: 3877, 0: 3548})\n",
            "검증 데이터 레이블 비율 확인 : Counter({4: 77, 3: 22, 1: 20, 2: 19, 0: 18})\n",
            "테스트 데이터 레이블 비율 확인 : Counter({4: 77, 3: 22, 2: 20, 1: 19, 0: 18})\n"
          ]
        }
      ],
      "source": [
        "data_path = \"./finetuned_output_bert/senti_kor_sns_5000_bt.csv\" # 학습 데이터 위치\n",
        "load = DataLoad(data_path)\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = load.split(0.01)\n",
        "test_text = x_test.copy()\n",
        "num_labels = int(max(y_train) + 1)"
      ],
      "id": "_Px3nAKiTEOe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlCAo4aJ0qN5",
        "outputId": "9f3b99b0-3c9a-41db-c187-e14a2b2aa077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers_interpret import SequenceClassificationExplainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "\n",
        "# 저장했던 Huggingface 모델을 불러옵니다.\n",
        "path = \"./finetuned_output_bert\"\n",
        "model =  AutoModelForSequenceClassification.from_pretrained(path, from_tf=True) \n",
        "tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "\n",
        "#다중분류 설명자 생성\n",
        "multiclass_explainer = SequenceClassificationExplainer(model = model, \n",
        "                                                       tokenizer = tokenizer)"
      ],
      "id": "hlCAo4aJ0qN5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlLozE8E5hAf"
      },
      "source": [
        "transformers_interpret는 불러온 tokenizer를 기반으로 토큰화를 시키고 각 토큰마다 레이블에 끼치는 정도를 수치화하였습니다.\n",
        "- 수치가 높을 수록 해당 토큰은 클래스 선택에 긍정적인 영향을 끼쳣다고 봅니다.\n",
        "- 수치가 낮을 수록 해당 토큰은 클래스 선택에 부정적인 영향을 끼쳣다고 보니다.\n",
        "- 수치가 0에 가까울 수록 해당 토큰은 클래스 선택에 영향을 끼치지 않았다고 봅니다."
      ],
      "id": "rlLozE8E5hAf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "pJrhm0nP20XF",
        "outputId": "8bc3a41e-c0df-49d1-901e-d2e25d01e41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실제 레이블 : 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>4</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_4 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_4</b></text></td><td><text style=\"padding-right:2em\"><b>1.21</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 앞                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##집                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 할아버지                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 돌아가                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##셨                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##데                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 헤                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 갑자기                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 한참                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##됐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##단다                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 진짜                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 응                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##그래                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##서                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 안보                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##셨                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##나                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##보                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##다                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 결국                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 돌아가                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##셨                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##네                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 코                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##로나                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##땜                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##에                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 안나                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##오                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##나                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 했                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##거                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##든                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 지병                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##있                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##으                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##셨                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##나                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 뇌졸중                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 오래                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##살                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##수                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##가                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##없                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##어                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 뇌졸중                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##와서                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 몸                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그랬었                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##잖아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그래도                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 잘                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##걷                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##고                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##다니                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##시                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##더                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##만                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그래도                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 몇                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##년                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##봤                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##다고                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좀                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그렇                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##네                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 맘                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 응                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그렇게                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아파                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##도                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 참                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 깔끔                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##하                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##시                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##드                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##만                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 순리                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##지                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 뭐                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "i = 3\n",
        "sample = x_test[i]\n",
        "sample_label = y_test[i]\n",
        "print(f\"실제 레이블 : {sample_label}\")\n",
        "\n",
        "word_attributions = multiclass_explainer(sample)\n",
        "html = multiclass_explainer.visualize()"
      ],
      "id": "pJrhm0nP20XF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "gfAO3BoM3Ubl",
        "outputId": "bc065fbc-a4cc-44c9-b738-13dff6ac6a7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_2 (0.97)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_2</b></text></td><td><text style=\"padding-right:2em\"><b>2.93</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 지은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 63%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##씨                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 이번                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 주말                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##에                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 뭐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 해요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 저                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 약속                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##은                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 없                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##어요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그러면                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 같이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 영화                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##볼                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##래요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 요즘                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 재미있                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##는                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 영화                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##있                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##나                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 마블                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좋아하                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##세요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 요즘                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 마블                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##영화                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 많이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 보                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##던                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##데                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 저                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##는                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 별로                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 안                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##좋                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##해                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좋아하                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##세요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 저                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##도                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 챙겨                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##보                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##지                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##는                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 않                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그러면                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 같이                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 뮤지컬                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##봐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 뮤지컬                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좋아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그러면                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 토요일                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##로                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 제                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##가                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 티켓                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 예매                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##할                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##게요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 감사                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##합니다                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그때                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [UNK]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "i = 414\n",
        "sample = test_set[\"text\"]\n",
        "\n",
        "sample = sample[i]\n",
        "#sample_label = y_test[i]\n",
        "\n",
        "#print(f\"실제 레이블 : {sample_label}\")\n",
        "\n",
        "word_attributions = multiclass_explainer(sample)\n",
        "html = multiclass_explainer.visualize()"
      ],
      "id": "gfAO3BoM3Ubl"
    },
    {
      "cell_type": "code",
      "source": [
        "i= 450\n",
        "sample = test_set[\"text\"]\n",
        "\n",
        "sample = sample[i]\n",
        "#sample_label = y_test[i]\n",
        "\n",
        "#print(f\"실제 레이블 : {sample_label}\")\n",
        "\n",
        "word_attributions = multiclass_explainer(sample)\n",
        "html = multiclass_explainer.visualize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "ny1NX7rVlNuf",
        "outputId": "b6c83c0a-5659-4f90-a732-e2b966aecc1d"
      },
      "id": "ny1NX7rVlNuf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>4.88</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 같이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 게임                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##하                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##게                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 몇                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 번                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 방                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##으로                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 들어와                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 나                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 오늘                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 학원                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 가야                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 돼서                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 못                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 들어                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 갈                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 것                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 같                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 까                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##불                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##지                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 말                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##고                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좋                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 말                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##로                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 할                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 때                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 들어와                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##라                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 정말                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##야                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 야                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 오늘                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 학원                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 가야                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 해                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그럼                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 내                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아이템                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 누가                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 결제                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##해                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##주                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##냐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 오늘                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 나                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 용돈                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 못                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 받                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##았                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##어                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그건                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 나                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 알바                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아니                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##고                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 저번                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##에도                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 사                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##줬                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##잖아                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##땐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그때                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 고                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 이번                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##에도                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 부탁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좀                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 하자                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좋                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 말                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##로                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 할                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 때                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 이번                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 진짜                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 마지막                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##야                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 32\n",
        "\n",
        "sample = test_set[\"text\"]\n",
        "\n",
        "sample = sample[i]\n",
        "#sample_label = y_test[i]\n",
        "\n",
        "#print(f\"실제 레이블 : {sample_label}\")\n",
        "\n",
        "word_attributions = multiclass_explainer(sample)\n",
        "html = multiclass_explainer.visualize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ligFIS6xlN3E",
        "outputId": "4f82613d-ee6f-4627-b497-11783fb3c8f0"
      },
      "id": "ligFIS6xlN3E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>3</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_3 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_3</b></text></td><td><text style=\"padding-right:2em\"><b>4.16</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 빠                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##끄                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 뭐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##해                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 빠                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##끄                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##빠                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##끄                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 거려                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 염                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##따                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##형                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 모르                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##냐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 몰라                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그게                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 누군                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##데                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 랩                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##퍼                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##자                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 유                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##튜                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##버                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 재밌                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##어                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 관심                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##없                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##다                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 빠                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##끄                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 제발                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 알                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##았                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##어                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 안                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##할                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##게                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 빠                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##끄                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 꺼져                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 쫌                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 401\n",
        "\n",
        "sample = test_set[\"text\"]\n",
        "\n",
        "sample = sample[i]\n",
        "#sample_label = y_test[i]\n",
        "\n",
        "#print(f\"실제 레이블 : {sample_label}\")\n",
        "\n",
        "word_attributions = multiclass_explainer(sample)\n",
        "html = multiclass_explainer.visualize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "rXFKmAiZoP3g",
        "outputId": "637d570b-c3be-4465-b1b4-82097bb4599a"
      },
      "id": "rXFKmAiZoP3g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>3</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_3 (0.98)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_3</b></text></td><td><text style=\"padding-right:2em\"><b>6.29</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 손                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 왜                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##그러                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##세요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 조금                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 다쳤                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##어요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 그러                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##시                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##구나                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 우리                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##애                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##가                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 놀래                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##서                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 안보                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##게                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 주머니                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##에                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좀                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 넣                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##으                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##세요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 네                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 손                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##좀                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 가리                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##시                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##라                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##구요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 제                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##가                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##왜                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 저희                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 애                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##가                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 놀래                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##니까                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 애                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##랑                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 다른                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##곳                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##으로                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 가세                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 저희                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##는                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 둘                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##잖아요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아프                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##신                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아니                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 혼자                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##신                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##분                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 좀                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 가세                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 애                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##가                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 참                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 잘                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##배우                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##겠                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##네                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##요                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 잘못되어진 label 별로 확인\n",
        " 오판한 사례들을 모아서 오판한 사례진단.  \n",
        " (굵직한 힌트들만 정리)\n",
        "\n",
        "사례 정리  \n",
        "1) 회사와 관련된 표현들 (~~씨, 대리 , 미팅, 퇴근 ,망했)   \n",
        "2) 돈을 빌리거나하는 부탁의 대화 or 용돈 , 카드, 이쁘다, 비싼 ,수술비, 입금,만원 같은 금전적 단어 갈취로 분리  \n",
        "3) 맥락 못 잡으면 기타괴롭힘으로 분류해버림"
      ],
      "metadata": {
        "id": "sOqou7zVjNqR"
      },
      "id": "sOqou7zVjNqR"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bsbL0H2PlLZF"
      },
      "id": "bsbL0H2PlLZF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ObCwvxwgbkhf"
      },
      "id": "ObCwvxwgbkhf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP_t_QBT0B5l"
      },
      "source": [
        "## 6. 리더보드용 데이터 test.json 예측"
      ],
      "id": "cP_t_QBT0B5l"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFk8Gi9I-QG2"
      },
      "source": [
        "리더보드용 데이터인 test.json 파일을 불러와서 앞서 훈련 데이터에서 적용된 전처리를 동일하게 해줍니다."
      ],
      "id": "ZFk8Gi9I-QG2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otOol1-V2Uit",
        "outputId": "822b97ea-a96f-4648-e715-b2d2ca931f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수 : 500\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "test_path = \"./test.json\"\n",
        "with open(test_path, \"r\", encoding = \"utf-8\") as st_json:\n",
        "    test = json.load(st_json)\n",
        "print(f\"테스트 데이터 개수 : {len(test)}\")    "
      ],
      "id": "otOol1-V2Uit"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nuYOIp31_Sl8",
        "outputId": "7ef848db-d251-4edc-f935-34971d280e4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-14a51034-f4d0-4104-9b41-c858bee464e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>t_000</th>\n",
              "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t_001</th>\n",
              "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t_002</th>\n",
              "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t_003</th>\n",
              "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t_004</th>\n",
              "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14a51034-f4d0-4104-9b41-c858bee464e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14a51034-f4d0-4104-9b41-c858bee464e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14a51034-f4d0-4104-9b41-c858bee464e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text\n",
              "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...\n",
              "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...\n",
              "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...\n",
              "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...\n",
              "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도..."
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "def remove_punctuation(x):\n",
        "  x = re.sub(\"[^ㄱ-ㅎ가-힣0-9]+\", \" \", x)\n",
        "  x = re.sub(\"[ ]+\", \" \", x)\n",
        "  x = x.strip()\n",
        "  return x\n",
        "\n",
        "test_set = pd.DataFrame()\n",
        "test_set[\"text\"] = pd.read_json(test_path).T[\"text\"]\n",
        "test_set.head()"
      ],
      "id": "nuYOIp31_Sl8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WyFSmsc-Zhj"
      },
      "source": [
        "전처리가 완료된 test.json의 데이터를 훈련 데이터로 학습되어진 분류모델로 레이블을 예측시켜줍니다.\n",
        "1. BERT 모델로 예측하는 경우"
      ],
      "id": "7WyFSmsc-Zhj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "3IZj5BwHUpFK",
        "outputId": "d6989cc0-89ed-46dd-b4ba-1af7f986c707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ./tapt_output_bert and are newly initialized: ['classifier', 'bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-e4c5020daf8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"GPT\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-9533fb2ab0f3>\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(self, X, Y, lstm)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# BERT 모델인 경우 텐서플로우 데이터셋으로 반환시킵니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m       dataset = tf.data.Dataset.from_tensor_slices((dict(encodings), \n\u001b[1;32m    107\u001b[0m                                                           Y))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2458\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2459\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2460\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2461\u001b[0m             )\n\u001b[1;32m   2462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2652\u001b[0m         )\n\u001b[1;32m   2653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mis_pretokenized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         )\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_path = \"./finetuned_output_bert\" \n",
        "batch_size = 16 # 모델에 들어가는 배치 크기\n",
        "epochs = 2 # 에폭 수\n",
        "sub_ratio = [0.05, 0.1, 0.1]   \n",
        "pipeline = TrainPipeline(model_path, num_labels, batch_size, epochs)\n",
        "train_dataset = pipeline.dataset(x_train, y_train)\n",
        "val_dataset = pipeline.dataset(x_val, y_val)\n",
        "if \"GPT\" in str(pipeline.model):\n",
        "  test_dataset = pipeline.dataset(x_test, y_test)\n",
        "  x_test, y_test = test_dataset"
      ],
      "id": "3IZj5BwHUpFK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BBnzS4K5eXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89130f08-a14f-43f0-c376-62f440a19fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./finetuned_output_bert 추론...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at ./finetuned_output_bert were not used when initializing TFBertForSequenceClassification: ['dropout_301']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ./finetuned_output_bert.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
            "100%|██████████| 500/500 [02:52<00:00,  2.89it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 101, 1: 108, 2: 107, 3: 99, 4: 85})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "from glob import glob\n",
        "from copy import deepcopy\n",
        "from collections import Counter\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "\n",
        "model_path = \"./finetuned_output_bert\"\n",
        "print(f\"{model_path} 추론...\")\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "loaded_model = TFAutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# BERT\n",
        "text_classifier = TextClassificationPipeline(\n",
        "    tokenizer=loaded_tokenizer, \n",
        "    model=loaded_model, \n",
        "    framework='tf',\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "tqdm.pandas()\n",
        "tmp = test_set[\"text\"].progress_apply(lambda x : text_classifier(x))\n",
        "tmp = tmp.apply(lambda x : x[0])\n",
        "tmp = tmp.apply(lambda y : list(map(lambda x : x[\"score\"], y)))\n",
        "test_set[\"class\"] = tmp\n",
        "test_set[\"label_class\"] = test_set[\"class\"].apply(lambda x : np.argmax(x))\n",
        "labels = pd.DataFrame(tmp.tolist()).add_prefix(\"label_\")\n",
        "labels.index = test_set.index\n",
        "test_set = pd.concat([test_set, labels], axis = 1)\n",
        "Counter(test_set[\"label_class\"])"
      ],
      "id": "0BBnzS4K5eXA"
    },
    {
      "cell_type": "code",
      "source": [
        "test_set[\"text\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "rqdJWcSPbZkY",
        "outputId": "e5e7dde1-aec2-4826-85c1-d13763ca8388"
      },
      "id": "rqdJWcSPbZkY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나보네 그럼 취소할까요 아가씨 내 여기단골이니 담에 갖다줄께 저도 알바생이라 외상안됩니다 아따 누가 떼먹는다고 그러나 갖다준다고 안됩니다 자꾸이럼 경찰불러요 아가씨 담배피는교 그건 왜 물으세요 그람 아가씨 담배 한대만 빌립시다 내 지금 지갑도 잃어버리고 기분이 그래서 그러니 여기요  아따 주는김에 한개더 주면 되겠네'"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD8uT79e_g2W"
      },
      "source": [
        "2. GPT 모델로 예측하는 경우"
      ],
      "id": "gD8uT79e_g2W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "pTJAi6zwuK1i",
        "outputId": "b3f8740c-71cd-4cfd-c0db-79d0e5fa06e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 944.31it/s]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ebcb01b684b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtest_set2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtest_set2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TFSequenceClassifierOutput' object has no attribute 'tolist'"
          ]
        }
      ],
      "source": [
        "# GPT\n",
        "test_set2 = deepcopy(test_set[\"text\"])\n",
        "test_set2 = pd.DataFrame({\"text\": test_set2})\n",
        "input_ids = []\n",
        "for example in tqdm(test_set2[\"text\"]):\n",
        "    bos_token = [pipeline.tokenizer.bos_token]\n",
        "    eos_token = [pipeline.tokenizer.eos_token]\n",
        "    tokens = bos_token + pipeline.tokenizer.tokenize(example) + eos_token\n",
        "    input_id = pipeline.tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids.append(input_id)\n",
        "\n",
        "max_seq_len = max(map(lambda x : len(x), input_ids))\n",
        "input_ids = pad_sequences(input_ids, maxlen = max_seq_len, \n",
        "                          value = pipeline.tokenizer.pad_token_id, \n",
        "                          padding='post')\n",
        "\n",
        "tmp = pipeline.model.predict(input_ids)\n",
        "test_set2[\"class\"] = tmp.tolist()\n",
        "test_set2[\"label_class\"] = test_set2[\"class\"].apply(lambda x : np.argmax(x))\n",
        "labels = pd.DataFrame(tmp.tolist()).add_prefix(\"label_\")\n",
        "labels.index = test_set.index\n",
        "test_set2 = pd.concat([test_set2, labels], axis = 1)\n",
        "Counter(test_set2[\"class\"].apply(lambda x : np.argmax(x)))"
      ],
      "id": "pTJAi6zwuK1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZv4H8rilwQu"
      },
      "outputs": [],
      "source": [
        "test_set.to_csv(\"./model/Only_test_pred/klue_bert_test_aug3time.csv\")"
      ],
      "id": "nZv4H8rilwQu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWZ-Vw_xPfEL"
      },
      "outputs": [],
      "source": [
        "test_set[test_set[\"label_class\"] == 4].to_csv(\"./tmp.csv\")"
      ],
      "id": "SWZ-Vw_xPfEL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOcgM5CN_9um"
      },
      "source": [
        "## 7. Conclusion"
      ],
      "id": "OOcgM5CN_9um"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nc_MetSAPMV"
      },
      "source": [
        "현재 test.json 의 클래스 분포는 각 클래스별로 100개가 존재하기 때문에 각 클래스 별로 100개를 분류하면 좋은 모델이라고 볼 수 있습니다."
      ],
      "id": "0Nc_MetSAPMV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi9rVoT2n_7m"
      },
      "source": [
        "|데이터|모델|에폭|성능|참고|\n",
        "|-|-|-|-|-|\n",
        "|sns, kor 데이터 5117개|BERT|1|Counter({0: 71, 1: 138, 2: 125, 3: 96, 4: 70})|base|\n",
        "|sns, kor 데이터 5117개|BERT|3|Counter({0: 89, 1: 130, 2: 110, 3: 102, 4: 69})|학습률 스케줄러 lr : 0.5 </br> 2/23 submission : 0.829|\n",
        "|sns, kor 데이터 5117개|GPT|5|Counter({0: 100, 1: 115, 2: 120, 3: 112, 4: 53})|학습률 스케줄러 lr : 0.2|\n",
        "|sns, kor 데이터 5117개|BERT|5|Counter({0: 98, 1: 111, 2: 109, 3: 118, 4: 64})|학습률 스케줄러 lr : 0.2 |\n",
        "|sns, kor 데이터 5117개|BERT|4|Counter({0: 95, 1: 114, 2: 114, 3: 123, 4: 54})|학습률 스케줄러 lr : 0.2 </br>|\n",
        "|sns, kor 데이터 5117개|GPT </br> BERT|5|Counter({0: 99, 1: 107, 2: 113, 3: 118, 4: 63})|학습률 스케쥴러 lr : 0.2|\n",
        "|sns, kor 데이터 5117개|GPT </br> BERT|3/5|Counter({0: 97, 1: 108, 2: 118, 3: 121, 4: 56})|학습률 스케쥴러 lr : 0.2 </br>|\n",
        "|only sns 15000개|BERT|4/5|Counter({0: 93, 1: 111, 2: 114, 3: 123, 4: 59})|학습률 스케줄러 lr : 0.2|\n",
        "|sns, kor 데이터 5117개|BERT|4/5|Counter({0: 93, 1: 111, 2: 113, 3: 123, 4: 60})|학습률 스케쥴러  lr : 0.2|\n",
        "|sns 5437개, kor 5117개|BERT|3/5|Counter({0: 99, 1: 105, 2: 112, 3: 116, 4: 68})|학습률 스케쥴러  lr : 0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 320개 데이터 추가|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개|BERT|5/5|Counter({0: 95, 1: 108, 2: 108, 3: 112, 4: 77})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가 </br> 2/24 submission : 0.865|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개|GPT|4/5|Counter({0: 96, 1: 97, 2: 108, 3: 127, 4: 72})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개|Electra|5/5|Counter({0: 90, 1: 114, 2: 106, 3: 120, 4: 70})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개|RoBERTa|5/5|Counter({0: 262, 3: 147, 4: 91})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개|RoBERTa|5/5|Counter({0: 33, 1: 181, 2: 123, 3: 105, 4: 58})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가 </br> 무작위 단어 교체 증강 기법 3번 적용|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개|BERT|5/5|Counter({0: 95, 1: 102, 2: 110, 3: 119, 4: 74})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가 </br> 무작위 단어 교체 증강 기법 3번 적용|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개, 역번역 증강 3개 추가|BERT|4/5|Counter({0: 99, 1: 106, 2: 108, 3: 109, 4: 78})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개, 역번역 증강 3개 추가|GPT|3/5|Counter({0: 104, 1: 108, 2: 105, 3: 116, 4: 67})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개, koeda 증강 5개 추가|BERT|5/5|Counter({0: 98, 1: 110, 2: 107, 3: 124, 4: 61})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개,역번역 3개 koeda 증강 5개 추가|BERT|3/5|Counter({0: 98, 1: 115, 2: 114, 3: 117, 4: 56})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개,역번역 3개|BERT|4/5|Counter({0: 99, 1: 108, 2: 108, 3: 114, 4: 71})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가 </br> val_data 비율 0.01|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개,역번역 3개|BERT|4/10|Counter({0: 101, 1: 108, 2: 107, 3: 99, 4: 85})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가 </br> val_data 비율 0.01 </br> (TAPT) run_mlm.py로 학습시킨 BERT 모델 </br> 2/28 submission : ?|\n",
        "|sns, kor, sentiment 5000개, bert_pred_sns 350개|BERT|4/10|Counter({0: 102, 1: 99, 2: 103, 3: 120, 4: 76})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가 </br> val_data 비율 0.01 </br> (TAPT) run_mlm.py로 학습시킨 BERT 모델|\n",
        "|sns, kor, sentiment, summary 5000개, bert_pred_sns 350개,역번역 3개|BERT|8/10|Counter({0: 102, 1: 105, 2: 105, 3: 114, 4: 74})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가 </br> val_data 비율 0.01 </br> (TAPT) run_mlm.py로 학습시킨 BERT 모델|\n",
        "|sns, kor, sentiment, summary 5000개, bert_pred_sns 350개,역번역 3개|BERT|4|Counter({0: 103, 1: 107, 2: 109, 3: 109, 4: 72})|학습률 스케쥴러 lr :0.2 </br> SNS데이터에서 BERT로 일반대화를 분류하였을 때, 일반 대화가 아니라고 분류한 350개 데이터 추가 </br> val_data 비율 0.01 </br> (TAPT) run_mlm.py로 학습시킨 BERT 모델|"
      ],
      "id": "Zi9rVoT2n_7m"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwls3WqAA9Se"
      },
      "source": [
        "- 모델중에서는 기본 BERT 모델이 가장 괜찮은 성능을 보이는 것으로 볼 수 있습니다.\n",
        "- 모델의 성능의 개선은 AI-Hub에서 새로운 데이터를 추가할 수록 성능이 개선되는 것을 볼 수가 있었습니다. \n",
        "- 역번역 증강 데이터는 성능 개선에 영향을 준다. (before : 76 -> after : 85)\n",
        "- 일반 대화 데이터들을 사전학습 시키고 Fine-tuning을 진행하면 성능이 개선된다.  \n",
        " (before : Counter({0: 99, 1: 108, 2: 108, 3: 114, 4: 71}) -> after : \tCounter({0: 101, 1: 108, 2: 107, 3: 99, 4: 85}))"
      ],
      "id": "Cwls3WqAA9Se"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzC5H1hz9v-i"
      },
      "source": [
        "## 8. Submission 제출 코드"
      ],
      "id": "DzC5H1hz9v-i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQnL3aDHFgwG",
        "outputId": "c3c8d4f0-47b0-4e2b-f811-410a5cfc2d20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('t_000', {'class': '01'}),\n",
              " ('t_001', {'class': '02'}),\n",
              " ('t_002', {'class': '02'}),\n",
              " ('t_003', {'class': '04'}),\n",
              " ('t_004', {'class': '03'}),\n",
              " ('t_005', {'class': '00'}),\n",
              " ('t_006', {'class': '00'}),\n",
              " ('t_007', {'class': '01'}),\n",
              " ('t_008', {'class': '04'}),\n",
              " ('t_009', {'class': '01'})]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indexes = test_set.index\n",
        "\n",
        "answer = defaultdict()\n",
        "tmp = defaultdict()\n",
        "for idx, case in enumerate(indexes):\n",
        "  tmp = str(0) + str(test_set[\"label_class\"][idx])\n",
        "  answer[case] = dict({\"class\":tmp})\n",
        "answer = dict(answer)\n",
        "list(answer.items())[:10]"
      ],
      "id": "LQnL3aDHFgwG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXraFwu23dk2",
        "outputId": "e4d1b760-4831-420f-b89c-d96faf6e5f0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline.ipynb                          \u001b[0m\u001b[01;34mmodel\u001b[0m/\n",
            "checkpoint                              \u001b[01;34mpackages\u001b[0m/\n",
            "DataAugmentation.ipynb                  Park_json.ipynb\n",
            "data_merge                              \u001b[01;34mprototype_model\u001b[0m/\n",
            "doc2vec.model                           \u001b[01;34msubmission\u001b[0m/\n",
            "doc2vec.model.docvecs.vectors_docs.npy  submission_baseline.ipynb\n",
            "doc2vec.model.trainables.syn1neg.npy    submission_experiment.ipynb\n",
            "doc2vec.model.wv.vectors.npy            TAPT_exp.ipynb\n",
            "모델성능_비교표.ipynb                   train_baseline_after_midterm.ipynb\n"
          ]
        }
      ],
      "source": [
        "ls"
      ],
      "id": "YXraFwu23dk2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGjetqzv2uhQ"
      },
      "outputs": [],
      "source": [
        "test_set[test_set[\"label_class\"] == 4].to_csv(\"./tmp.csv\")"
      ],
      "id": "WGjetqzv2uhQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTPzNAdRHTN2"
      },
      "outputs": [],
      "source": [
        "with open('./submission/submission_0228_bert_valratio001_runmlm.json', 'w') as fp:\n",
        "    json.dump(answer, fp)"
      ],
      "id": "oTPzNAdRHTN2"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "n7C236xgpKES",
        "executive-tumor",
        "YSfkbxNodTU-",
        "LGnVrUzRdZCX",
        "rWcWSHaTdoiU",
        "w7Fmk8Z_ddet"
      ],
      "machine_shape": "hm",
      "name": "submission_experiment_for xai.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}